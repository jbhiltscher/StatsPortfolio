---
title: "Homework 2"
subtitle: <center> <h1>Simple Linear Regression Model Assumptions</h1> </center>
author: <center> < Jake Hiltscher > <center>
output: html_document
---

<style type="text/css">
h1.title {
  font-size: 40px;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
library(tidyverse)
library(ggfortify)
library(car)
```

## Data and Description

One key component of determining appropriate speed limits is the amount of distance that is required to stop at a given speed. For example, in residential neighborhoods, when pedestrians are commonly in the roadways, it is important to be able to stop in a very short distance to ensure pedestrian safety. The speed of vehicles may be useful for determining the distance required to stop at that given speed, which can aid public officials in determining speed limits.

The Stopping Distance data set compares the **distance (column 2)** (in feet) required for a car to stop on a certain rural road against the **speed (column 1)** (MPH) of the car. Download the StoppingDistance.txt file from Canvas, and put it in the same folder as this R Markdown file.

#### 0. Replace the text "< PUT YOUR NAME HERE >" (above next to "author:") with your full name.

#### 1. Read in the data set, and call the tibble "stop". Print a summary of the data and make sure the data makes sense.

```{r}
stop <- read.table("StoppingDistance.txt", header= TRUE)
summary(stop)
```

#### 2. Create a scatterplot of the data with variables on the appropriate axes (think about which variable makes the most sense to be the response). Make you plot look professional (make sure the axes labels are descriptive, the plot is square, etc.).

```{r, fig.align='center'}
library(ggplot2)
stop_base_plot <- ggplot(data = stop) + 
   geom_point(mapping = aes(x = Speed, y = Distance)) +
   theme(aspect.ratio = 1)
stop_base_plot
```

#### 3. Briefly describe the relationship between Speed and Distance. (Hint: you should use 2 or 3 key words.)

There is a positive correlation between speed and distance. As speed increases, Distance increases.

#### 4. Add the OLS regression line to the scatterplot you created in question 2 (note: if you receive a warning about rows with missing values, you may need to adjust an axis limit using `scale_y_continuous(limits = c(###, ###))`).

```{r, fig.align='center'}
stop_linear_model <- stop_base_plot + 
   geom_smooth(mapping = aes(x = Speed, y = Distance),
               method = "lm",
               se = FALSE)
stop_linear_model
```

#### 5. (a) Apply linear regression to the data(no transformations). (b) Print out a summary of the results from the `lm` function. (c) Save the residuals and fitted values to the `stop` tibble.

```{r}
stop_lm <- lm(Speed ~ Distance, data = stop)
summary(stop_lm)
stop$residuals <- stop_lm$residuals
stop$fittedDistance <- stop_lm$fitted.values
```

#### 6. Mathematically write out the fitted simple linear regression model for this data set using the coefficients you found above. Do not use "x" and "y" in your model - use variable names that are fairly descriptive, and do not use matrix notation.

$\text{Distance}_i$ $=$ $\beta_0$ $+$ $\beta_1$$\text{Speed}_i$ $+$ $\epsilon_i$



### Questions 7-12 involve using diagnostics to determine if the linear regression assumptions are met. For each assumption, (1) perform appropriate diagnostics to determine if the assumption is violated, and (2) explain whether or not you think the assumption is violated and why you think that.

#### 7. (L) X vs Y is linear (use at least two diagnostic tools)

```{r, fig.align='center'}
stop_base_plot

(stop_resid_fitted_plot <- autoplot(stop_lm, which = 1, ncol = 1, nrow = 1))

```

Linearity is not met here as you can see by the scatter plot and residual vs fitted plot. Lots of curve going on.

#### 8. (I) The residuals are independent (no diagnostic tools - just think about how the data was collected and briefly write your thoughts)

The residuals are independent. The data was randomly sampled and the other factors/variables don't provide bias.

#### 9. (N) The residuals are normally distributed and centered at zero (use at least three diagnostic tools)

```{r, fig.align='center'}
# save the plot as a variable since we will use it later for other assumptions
stop_hist <- ggplot(data = stop) + 
  # when using this code for future data sets, make sure to change the binwidth
  geom_histogram(mapping = aes(x = residuals, y = ..density..), 
                 binwidth = 2) +
  # stat_function() overlays the red normal curve on the histogram
  stat_function(fun = dnorm, 
                color = "red", 
                size = 2,
                args = list(mean = mean(stop$residuals), 
                            sd = sd(stop$residuals))) +
  theme(aspect.ratio = 1)
stop_hist

(stop_norm_plot <- autoplot(stop_lm, which = 2, ncol = 1, nrow = 1))

shapiro.test(stop$Distance)

```

< your response here >

#### 10. (E) The residuals have equal/constant variance across all values of X (use two diagnostic tools)

```{r, fig.align='center'}
stop_resid_fitted_plot

grp <- as.factor(c(rep("lower", floor(dim(stop)[1] / 2)), 
                   rep("upper", ceiling(dim(stop)[1] / 2))))

leveneTest(unlist(stop[order(stop$Distance), "residuals"]) ~ grp, 
           center = median)
```

< your response here >

#### 11. (A) The model describes all observations (i.e., there are no influential points) (use at least four diagnostic tools)

```{r, fig.align='center'}
stop_base_plot

stop_hist

stop_norm_plot

# calculate the DFFITS
stop$dffits <- dffits(stop_lm)

# plot the DFFITS against the observation number
ggplot(data = stop) + 
  geom_point(mapping = aes(x = as.numeric(rownames(stop)), 
                           y = abs(dffits))) +
  ylab("Absolute Value of DFFITS for Y") +
  xlab("Observation Number") +
  # for n > 30
  geom_hline(mapping = aes(yintercept = 2 * sqrt(length(stop_lm$coefficients) /
                                                   length(dffits))),
             color = "red", 
             linetype = "dashed") +
  # for n <= 30 (code for future, small data sets)
  # geom_hline(mapping = aes(yintercept = 1),
  #            color = "red", 
  #            linetype = "dashed") +
  theme(aspect.ratio = 1)

# print a list of potential influential points according to DFFITS
# for n > 30
stop %>% 
  mutate(rowNum = row.names(stop)) %>%  # save original row numbers 
  # select potential influential pts
  filter(abs(dffits) > 2 * sqrt(length(stop_lm$coefficients) / 
                                  length(dffits))) %>%
  arrange(desc(abs(dffits)))
```

There are three infulential points. Obsrevation numbers: 60, 62, 55.

#### 12. (R) Additional predictor variables are not required (no diagnostic tools - just think about the variables you have and if there are other variables you think would help predict the response)

Additional predictors are not required. However, I think some other variables that could explain some of the trend is incline or decline of surface, surface type, and tires (type and wear).

#### 13. Based on your analysis of the diagnostic measures, briefly discuss why this simple linear regression model on the raw data (not transformed) is *not* appropriate.

Linearity is not met, neither are the residuals normally distributed. There is an exponential trend

#### 14. Fix the model by making any necessary transformations. Justify the transformation you chose in words (why did you choose to transform just x, just y, or both?). (Note: if boxCox(mod) throws an error, replace mod with the formula for the linear model, y ~ x.) (Note: you will most likely need to repeat questions 14 and 18 until you are satisfied with the transformation you chose. Only then should you fill out this section - I only want to see the model you end up choosing, not all of your attempted models.)

```{r, fig.align='center'}
bc <- boxCox(stop$Distance ~ stop$Speed)  # plot curve
bc$x[which.max(bc$y)]  # pull out the "best" lambda value

stop$Distance_trans <- sqrt(stop$Distance)

stop_lm_trans <- lm(Speed ~ Distance_trans, data = stop)
summary(stop_lm_trans)
stop$residuals <- stop_lm_trans$residuals
stop$fittedMPG <- stop_lm_trans$fitted.values
stop_trans_base_plot <- ggplot(data = stop) + 
   geom_point(mapping = aes(x = Speed, y = Distance_trans)) +
   theme(aspect.ratio = 1)+
  ylab("sqrt(Distance)")

stop_trans_base_plot

```

I transformed the data by square rooting the y-values (Distance).

### Now, in Questions 15-18, re-check your transformed model and verify that the assumptions (the assumptions that were addressed in the questions above) are met. Provide a brief discussion about how each of the previously violated assumptions are now satisfied. Also, provide the code you used to assess adherence to the assumptions. (Note that transforming will not change your responses about (I) the residuals being independent and (R) additional predictor variables not being required, so we will skip these assumptions here.)

#### 15. (L) Linearity (use at least two diagnostic tools)

```{r, fig.align='center'}
stop_trans_base_plot

(stop_resid_fitted_plot_trans <- autoplot(stop_lm_trans, which = 1, ncol = 1, nrow = 1))

```

The scatter plot shows the data are more linear now, rather than curved in the original. The residual vs fitted line is also along the 0 line without the curves in the original as well.

#### 16.  (N) The residuals are normally distributed and centered at zero (use at least three diagnostic tools)

```{r, fig.align='center'}
# save the plot as a variable since we will use it later for other assumptions
stop_hist_trans <- ggplot(data = stop) + 
  # when using this code for future data sets, make sure to change the binwidth
  geom_histogram(mapping = aes(x = residuals, y = ..density..), 
                 binwidth = 2) +
  # stat_function() overlays the red normal curve on the histogram
  stat_function(fun = dnorm, 
                color = "red", 
                size = 2,
                args = list(mean = mean(stop$residuals), 
                            sd = sd(stop$residuals))) +
  theme(aspect.ratio = 1)
stop_hist_trans

(stop_norm_plot_trans <- autoplot(stop_lm_trans, which = 2, ncol = 1, nrow = 1))

shapiro.test(stop$Distance_trans)
```

The new model demonstrates normality, QQ Plot is a pretty straight line and the histogram shows that the residuals are close to 0.

#### 17. (E) The residuals have equal/constant variance across all values of X (use two diagnostic tools)

```{r, fig.align='center'}
stop_resid_fitted_plot_trans

grp <- as.factor(c(rep("lower", floor(dim(stop)[1] / 2)), 
                   rep("upper", ceiling(dim(stop)[1] / 2))))
leveneTest(unlist(stop[order(stop$Distance_trans), "residuals"]) ~ grp, 
           center = median)
```

The new model's residuals have equal constant value. The points are scattered evenly, making the trend line close to a slope of zero consistently.

#### 18. (A) The model describes all observations (i.e., there are no influential points) (use at least four diagnostic tools)

```{r, fig.align='center'}
stop_trans_base_plot

stop_hist_trans

stop_norm_plot_trans

# calculate the DFFITS
stop$dffits <- dffits(stop_lm_trans)

# plot the DFFITS against the observation number
ggplot(data = stop) + 
  geom_point(mapping = aes(x = as.numeric(rownames(stop)), 
                           y = abs(dffits))) +
  ylab("Absolute Value of DFFITS for Y") +
  xlab("Observation Number") +
  # for n > 30
  geom_hline(mapping = aes(yintercept = 2 * sqrt(length(stop_lm_trans$coefficients) /
                                                   length(dffits))),
             color = "red", 
             linetype = "dashed") +
  # for n <= 30 (code for future, small data sets)
  # geom_hline(mapping = aes(yintercept = 1),
  #            color = "red", 
  #            linetype = "dashed") +
  theme(aspect.ratio = 1)

# print a list of potential influential points according to DFFITS
# for n > 30
stop %>% 
  mutate(rowNum = row.names(stop)) %>%  # save original row numbers 
  # select potential influential pts
  filter(abs(dffits) > 2 * sqrt(length(stop_lm_trans$coefficients) / 
                                  length(dffits))) %>%
  arrange(desc(abs(dffits)))
```

The plots show us that the new model describes all the observations. The DFFITS red line was raised which makes the influential points from the original data not have as much of an effect.

#### 19. Mathematically write out the fitted simple linear regression model for this data set using the coefficients you found above from your transformed model. Do not use "x" and "y" in your model - use variable names that are fairly descriptive, and do not use matrix notation.

$\text{sqrt(Distance}_i)$ $=$ $\beta_0$ $+$ $\beta_1$$\text{Speed}_i$ $+$ $\epsilon_i$


#### 20. Plot your new fitted *curve* on the scatterplot of the original data (on the original scale - not the transformed scale). Do you think this curve fits the data better than the line you previously fit?

```{r}
stop_linear_model_trans <- stop_base_plot + 
   geom_smooth(mapping = aes(x = Speed, y = Distance),
               method = "lm",formula = (-1.9995 + 3.6643*stop$Distance)^2, 
               se = FALSE)
stop_linear_model_trans
```

I couldn't get it to work, but it would work and look better in theory.

#### 21. Briefly summarize what you learned, personally, from this analysis about the statistics, model fitting process, etc.

I learned that transformations make more sense. I thought I was kind of a waste of time to change the model. But I understand it more clearly, that the assumptions need to be met in order to have a valid data set, without influence points and other underlying bias.

#### 22. Briefly summarize what you learned from this analysis *to a non-statistician*. Write a few sentences about (1) the purpose of this data set and analysis and (2) what you learned about this data set from your analysis. Write your response as if you were addressing a business manager (avoid using statistics jargon) and just provide the main take-aways.

The purpose of this analysis was to take a step back and look more into the data, running diagnostics to see if there were any issues with our current models. 
I learned, after making some adjustments to the data set, that as the speed of the vehicle was increased, the distance to come to a complete stop increased. 
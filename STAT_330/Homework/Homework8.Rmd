---
title: "Homework 8"
subtitle: <center> <h1>Poisson Regression</h1> </center>
author: <center> Jake Hiltscher <center>
output: html_document
---

<style type="text/css">
h1.title {
font-size: 40px;
text-align: center;
}
</style>

```{r setup, include=FALSE}
# load packages here
library(tidyverse)
library(corrplot)  # for the correlation matrix
library(bestglm)  # for variable selection
library(car)  # for VIFs
library(gridExtra)
library(lmtest)
```

## Data and Description

Bike sharing systems are the new generation of traditional bike rentals where the process from membership, rental and return back has become automatic. Through these systems, users are able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bikesharing programs around the world which is composed of over 500,000 bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.

The bike-sharing rental process is highly correlated with environmental and seasonal settings. For instance, weather conditions, precipitation, day of week, season, hour of the day, etc. can affect the volume of rentals. This dataset is composed from the two-year historical data corresponding to years 2011 and 2012 from the Capital Bikeshare system in Washington D.C. The daily counts of the number of bikes used was extracted and then the corresponding weather and seasonal information was added.

The data set has information for 731 days and contains the following variables:

Variable   | Description
---------- | -------------
season     | Season (Fall, Spring, Summer, Winter)
yr         | Year (2011, 2012)
holiday    | Was the day a holiday (Yes/No)?
workingday | Was the day a working day (Yes/No)? (Yes if the day is neither a weekend nor a holiday)
weathersit | Weather (Clear, Light Precip, Misty)
temp       | Normalized temperature in Celsius
hum        | Normalized humidity
windspeed  | Normalized windspeed
cnt        | Number of bikes rented

The data can be found in the Bikes data set on Canvas. Download Bikes.csv, and put it in the same folder as this R Markdown file.

#### 0. Replace the text "< PUT YOUR NAME HERE >" (above next to "author:") with your full name.

#### 1. Read in the data set, and call the data frame "bikes". Make sure the yr and character variables are factors (if they are not, you'll need to make them factors). Print a summary of the data and make sure the data makes sense.

```{r}
bikes <- read_csv("Bikes.csv") %>% 
  mutate_if(is.character, as.factor) %>% mutate(yr = as.factor(yr))
summary(bikes)
```

#### 2. Explore the data: create a histogram for the response. *Briefly describe the shape of the distribution - you should mention (1) symmetry or skewness, (2) the number of modes, and (3) potential outliers.*

```{r, fig.align='center'}
bikes_hist <- ggplot(data = bikes) + 
  geom_histogram(mapping = aes(x = cnt, y = ..density..),
                 binwidth = 200) +
  theme_bw() + 
  theme(aspect.ratio = 1)
bikes_hist
```

The histogram is pretty symmetrical, even with the two "bumps" on both sides. There's three modes in the graph. I think there's an outlierr at around 0 but it's hard to tell, I would need another graphic to look into it more.

#### 3. Briefly explain why traditional multiple linear regression methods are not suitable for *this* data set. You should mention at least two of the reasons we discussed in class (*your reasons should refer to this data set (i.e. be specific, not general)*).

Traditional multiple linear regression wouldn't work as well as Poisson because there are multiple categorical factors that will lead to homoscedasticity and errors won't be normally distributed.

#### 4. Use a variable selection procedure to help you decide which, if any, variables to omit from the Poisson regression model you will soon fit. You may choose which selection method to use (best subsets, forward, backward, sequential replacement, LASSO, or elastic net) and which metric/criteria to use (AIC, BIC, or CV/PMSE).

```{r, fig.align='center'}
bikes_best_subsets_bic <- bestglm(as.data.frame(bikes),
                                  IC = "BIC",
                                  method = "exhaustive",
                                  TopModels = 1,
                                  family = poisson)
summary(bikes_best_subsets_bic$BestModel)
```

#### 5. Write out the Poisson regression model for this data set using the covariates that you see fit. You should use parameters/Greek letters (NOT the "fitted" model using numbers...since you have not fit a model yet;) ). Be sure to use indicator variables, if necessary. (You will need to split the equation on multiple lines to have it render properly as an HTML file.)

$log(\mu_i)$ $=$ $\beta_0$ $+$ $\beta_1$$I(\text{Season}_i = Fall)$ $+$
$\beta_2$$I(\text{Year}_i = 2011)$ $+$ $\beta_3$$I(\text{Holiday}_i = No)$ $+$
$\beta_4$$I(\text{WorkingDay}_i = No)$ $+$ $\beta_5$$I(\text{Weather}_i = Clear)$ $+$
$\beta_6$$\text{Temperature}_i$ $+$ $\beta_7$$\text{Humidity}_i$ $+$
$\beta_8$$\text{WindSpeed}_i$

#### 6. Fit a Poisson regression model using the covariates that you used in the previous question (use the `glm` function - do not just call the result from the variable selection procedure). Print a summary of the results.

```{r, fig.align='center'}

bikes_poisson <- glm(cnt ~ ., family = poisson, data = bikes)

summary(bikes_poisson)
```





### The next several questions involve using diagnostics to check the Poisson regression model assumptions. For each assumption, (1) code the diagnostic(s) that I indicate (next to the assumption in parentheses) to determine if the assumption is violated, and (2) explain whether or not you think the assumption is violated and why you think that.




#### 7. The X's vs log(y) are linear (use scatterplots and partial regression (added-variable) plots)

```{r, fig.align='center'}
scatter_temp <- ggplot(bikes, aes(temp, cnt)) +
  geom_point()

scatter_hum <- ggplot(bikes, aes(hum, cnt)) +
  geom_point()

scatter_windspeed <- ggplot(bikes, aes(windspeed, cnt)) +
  geom_point()

grid.arrange(scatter_temp,
             scatter_hum,
             scatter_windspeed,
             nrow = 2)

```

Temp has a curve to it, hum and windspeed seem to be random. I would say this assumption is met.

#### 8. The residuals are independent (no diagnostic tools - just think about how the data was collected and briefly write your thoughts)

This assumption is met. There isn't any skewness or anything that would affect the data.

#### 9. The model describes all observations (i.e., there are no influential points) (use DFFITS)

```{r, fig.align='center'}
bikes$dffits <- dffits(bikes_poisson)

 ggplot(data = bikes) + 
   geom_point(mapping = aes(x = as.numeric(rownames(bikes)), 
                            y = abs(dffits))) +
   ylab("Absolute Value of DFFITS for cnt") +
   xlab("Observation Number") +
   # for n > 30
   geom_hline(mapping = aes(yintercept = 2 * sqrt(length(bikes_poisson$coefficients) /
                                                    length(dffits))),
              color = "red", 
              linetype = "dashed") +
   theme(aspect.ratio = 1)
```

There's one influential point at around observation number 650-700 ish. This assumption is not met.

#### 10. Additional predictor variables are not required (no diagnostic tools - just think about the variables you have and if there are other variables you think would help predict the response)

I think there could be something else that could effect the bike rentals, like location of the store. It effect weather and season (winter isn't really winter in California).

#### 11. No multicollinearity (use variance inflation factors)

```{r, fig.align='center'}
vif(bikes_poisson)
```

The mean is less than 2 and the max value is < 10 so there is no multicollinearity.

#### 12. Mean = Variance (no overdispersion/underdispersion) (use the three methods discussed in class)
```{r, fig.align='center'}
# your code here
x_qchisq <- seq(0, 1, by = 0.01) 
y_qchisq <- qchisq(x_qchisq, df = 11)  # Apply qchisq function
plot(y_qchisq)

model_2 <- update(bikes_poisson, .~. - temp)
anova(model_2, bikes_poisson, test="Chisq")

bikes_quasi <- glm(cnt ~ ., family = quasipoisson, data = bikes)
summary(bikes_quasi)
```

There is over dispersion because 20.99 is >> 1.




### Regardless of your assessment of the assumptions, proceed as if all assumptions were met.






#### 13. For the coefficient for holiday, compute (and output) $\beta_{holiday}$ (pull this value from the model output), $\exp\{\beta_{holiday}\}$, and $100 \times (\exp\{\beta_{holiday}\} - 1)%$.

```{r, fig.align='center'}
beta_holiday <- bikes_poisson$coefficients["holidayYes"]
beta_holiday

1/exp(beta_holiday)

100 * (1/exp(beta_holiday)-1)
```

#### 14. Interpret the coefficient for holiday based on the last TWO different ways we discussed in class (for negative coefficients).

*Interpretation 1:* Holding all else constant, the average number of rented bikes is 1/exp(-0.1654263) = 1.179896 times larger for holidays compared to non-holidays.

*Interpretation 2:* Holding all else constant, the average number of rented bikes increases by 100 x (1/exp(-0.1654263)-1) = 17.99% for holidays compared to non-holidays.

#### 15. Create (and output) 95% confidence intervals for $\beta_k$, $\exp\{\beta_k\}$, and $100 \times (\exp\{\beta_k\} - 1)%$ for all predictors using the `confint` function.

```{r, fig.align='center'}
confint(bikes_poisson, level = 0.95)
```

#### 16. Interpret the 95% confidence intervals for temp for $\beta_{temp}$, $\exp\{\beta_{temp}\}$, and $100 \times (\exp\{\beta_{temp}\} - 1)%$ (three interpretations total).

*Interpretation using $\beta_{temp}$:* Holding all else constant, the average number of rented bikes is between 1.21 and 1.23 times larger as temperature increases by 1 unit.

*Interpretation using $\exp\{\beta_{temp}\}$:* Holding all else constant, the average number of rented bikes increase between exp(1.21)=3.35 and exp(1.23)=3.42 as temperature increases by 1 unit.

*Interpretation using $100 \times (\exp\{\beta_{temp}\} - 1)%$:* Holding all else constant, the average number of rented bikes is between 12.1% and 12.3% larger as temperature increases by 1 unit.

#### 17. Calculate (and output) a 95% confidence interval (and point estimate) for the predicted average number of bike rentals for a day where season = "Spring", yr = "2012", holiday = "No", workingday = "Yes", weathersit = "Misty", temp = 0.34, hum = 0.80, and windspeed = 0.18. Note that you may not need to use all of these values depending on the variables you chose to include in your model. *Interpret the interval.*

```{r, fig.align='center'}
predict(bikes_poisson, 
        newdata = data.frame(season = "Spring", yr = "2012", holiday = "No", workingday = "Yes", weathersit = "Misty", temp = 0.34, hum = 0.80, windspeed = 0.18),
        level = 0.95,
        interval = "confidence",
        type = "response")
```

We are 95% confident that the number of rented bikes was between 2990 and 3143 when it's Spring, in the year 2012, it wasn't a holiday and a working day, as well as misty weather, with a temp of 0.34, humidity of 0.8, and a windspeed of 0.18.

#### 18. Compute (and output) the likelihood ratio test statistic for the model, and compute (and output) the associated $p$-value. Based on the results, what do you conclude?

```{r, fig.align='center'}
full_model <- glm(cnt ~ ., data = bikes)
lr.stat <- lrtest(full_model, bikes_poisson)
lr.stat
```

The p-value is > 0.05, meaning we will reject the null hypothesis

#### 19. Compute (and output) the pseudo $R^2$ value for the model.

```{r, fig.align='center'}
with(summary(bikes_poisson), 1-deviance/null.deviance)
```

#### 20. Briefly summarize what you learned, personally, from this analysis about the statistics, model fitting process, etc.

I find it interesting in the data that none of the variables were dropped with best subset. I think it's a rare thing to have it all line up like that.

#### 21. Briefly summarize what you learned from this analysis *to a non-statistician*. Write a few sentences about (1) the purpose of this data set and analysis and (2) what you learned about this data set from your analysis. Write your response as if you were addressing a business manager (avoid using statistics jargon) and just provide the main take-aways.

The dataset and analysis purpose is to show what influences the number of bike rentals.

The most significant varaible is temperature. It has the biggest effect on bike rentals.